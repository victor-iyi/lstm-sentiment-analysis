{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Sentiment Analysis with LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nltk import word_tokenize\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# directories\n",
    "saved_dir = 'saved/'\n",
    "model_dir = 'models/'\n",
    "dataset_dir = 'datasets/'\n",
    "tensorboard_dir = 'tensorboard/'\n",
    "chkpt_dir = os.path.join(tensorboard_dir, 'chkpt/')\n",
    "\n",
    "# dataset\n",
    "pos_dir = os.path.join(dataset_dir, 'positiveReviews')\n",
    "neg_dir = os.path.join(dataset_dir, 'negativeReviews')\n",
    "\n",
    "# saved files\n",
    "word_list_file = os.path.join(saved_dir, 'wordsList.npy')\n",
    "word_vector_file = os.path.join(saved_dir, 'wordVectors.npy')\n",
    "ids_matrix_file = os.path.join(saved_dir, 'idsMatrix.npy')\n",
    "\n",
    "# log files\n",
    "log_path = os.path.join(tensorboard_dir, '{:%d-%b-%Y  %H-%M-%S-%p}'.format(dt.datetime.now()))\n",
    "pre_trained_path = os.path.join(chkpt_dir, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### word lists and embedding matrix (word vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\", 'for', '-', 'that', 'on', 'is', 'was', 'said', 'with', 'he', 'as', 'it', 'by', 'at', '(', ')', 'from', 'his', \"''\", '``', 'an', 'be', 'has', 'are', 'have', 'but', 'were', 'not', 'this', 'who', 'they', 'had', 'i', 'which', 'will', 'their', ':', 'or', 'its', 'one', 'after']\n",
      "\n",
      "Word vector: (400000, 50)\n"
     ]
    }
   ],
   "source": [
    "# word lists\n",
    "word_list = np.load(word_list_file).tolist()\n",
    "word_list = [word.decode('UTF-8') for word in word_list]\n",
    "print(word_list[:50])\n",
    "\n",
    "# word vectors/embedding matrix\n",
    "word_vectors = np.load(word_vector_file)\n",
    "print('\\nWord vector: {:,}x{:,}'.format(*word_vectors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Converting words to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.21994001 -0.014414   -0.24502    -0.31895    -0.32942    -0.48162001\n",
      " -1.58179998  0.27079001 -1.36129999  0.05855    -0.10478    -0.44319001\n",
      " -0.40213001  0.05586     0.81841999  0.30684999 -1.00090003 -0.83020002\n",
      " -1.22590005  0.54736     0.60422999  0.33344999  0.02349    -0.58297998\n",
      "  0.068311   -1.49609995  0.12819    -0.18686    -0.17151     0.90003002\n",
      "  3.19050002 -0.59917003 -0.097557   -0.021908    0.54973    -0.14088\n",
      "  0.18978     0.34742999 -0.061865   -0.067381   -0.52579999  0.55704999\n",
      " -0.56489998 -0.42131001  0.24299     0.1408     -0.074287   -0.41503\n",
      " -0.17553    -0.62826002]\n"
     ]
    }
   ],
   "source": [
    "word = 'billion'\n",
    "word_idx = word_list.index(word.lower())\n",
    "print(word_vectors[word_idx])\n",
    "\n",
    "# Free memory\n",
    "del word\n",
    "del word_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Converting a sentence into `ids`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![Embedding lookup](Images/SentimentAnalysis5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pos_files = [os.path.join(pos_dir, f) \n",
    "             for f in os.listdir(pos_dir) \n",
    "             if f[0] != '.' and os.path.isfile(os.path.join(pos_dir, f))]\n",
    "neg_files = [os.path.join(neg_dir, f) \n",
    "             for f in os.listdir(neg_dir) \n",
    "             if f[0] != '.' and os.path.isfile(os.path.join(neg_dir, f))]\n",
    "# Combination\n",
    "files = pos_files + neg_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasets/positiveReviews/0_9.txt', 'datasets/positiveReviews/10000_8.txt'] \n",
      "12,500\n",
      "\n",
      "['datasets/negativeReviews/0_3.txt', 'datasets/negativeReviews/10000_4.txt'] \n",
      "12,500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('{}\\t{:,}\\n'.format(pos_files[:2], len(pos_files)))\n",
    "print('{}\\t{:,}\\n'.format(neg_files[:2], len(neg_files)))\n",
    "print('Total: {:,}'.format(len(files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Average and total number of words in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_num_words(data_files):\n",
    "    num_words = []\n",
    "    for df in data_files:\n",
    "        text = open(df, 'r', encoding='utf-8').read()\n",
    "        word_count = len(text.split())\n",
    "        num_words.append(word_count)\n",
    "        sys.stdout.write('\\r{:,} of {:,} files to go...'.format(i+1, len(data_files))\n",
    "    return num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with datasets positiveReviews\n",
      "Done with datasets negativeReviews\n"
     ]
    }
   ],
   "source": [
    "word_count = get_num_words(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files: 25,000\n",
      "Sum of words: 5,844,680\n",
      "Average words: 233.79\n"
     ]
    }
   ],
   "source": [
    "n_files = len(word_count)\n",
    "total = sum(word_count)\n",
    "avg = sum(word_count) / len(word_count)\n",
    "max_seq_len = 250 # int(avg)\n",
    "word_vector_dim = 300\n",
    "\n",
    "print('Total number of files: {:,}'.format(n_files))\n",
    "print('Sum of words: {:,}'.format(total))\n",
    "print('Average words: {:.02f}'.format(avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Plotting distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncIAxM7MsHGDMzCwLBxgzM8vi/wNtOwE+R/mYCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115ebd160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(word_count, 100, color='#a0a0a0')\n",
    "plt.xlabel('Sequence length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 1200)\n",
    "plt.title('Word frequency distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Free up memory\n",
    "\n",
    "del word_count\n",
    "del n_files\n",
    "del total\n",
    "del avg\n",
    "del pos_files\n",
    "del neg_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Looking into the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n"
     ]
    }
   ],
   "source": [
    "# Before cleaning\n",
    "print(open(files[0], 'r', encoding='utf-8').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cleaning up the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "special_chars = re.compile('[^A-Za-z0-9 ]+')\n",
    "\n",
    "def clean(string):\n",
    "    string = string.lower().replace('<br />', ' ')\n",
    "    return re.sub(special_chars, '', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell highs satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled  at  high a classic line inspector im here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isnt\n"
     ]
    }
   ],
   "source": [
    "# After cleaning\n",
    "print(clean(open(files[0], 'r', encoding='utf-8').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_ids(data_files, word_list, max_seq_len=250, **kwargs):\n",
    "    # retrieve keyword arugments\n",
    "    save_file = kwargs['save_file'] if 'save_file' in kwargs else 'saved/ids.npy'\n",
    "    force = kwargs['force'] if 'force' in kwargs else False\n",
    "    logging = kwargs['logging'] if 'logging' in kwargs else False\n",
    "    \n",
    "    # load saved file if it exist and we're not forcing an override\n",
    "    should_load_saved = os.path.isfile(save_file) and not force\n",
    "    if should_load_saved:\n",
    "        return np.load(save_file)\n",
    "    \n",
    "    # The file doesn't exist or we are forcing an override\n",
    "    num_files = len(data_files)\n",
    "    ids = np.zeros(shape=[num_files, max_seq_len], dtype=np.int32)\n",
    "    # converting data files to ids...\n",
    "    if logging:\n",
    "        print('Converting to ids: {}'.format(ids.shape))\n",
    "\n",
    "    for i, df in enumerate(data_files):\n",
    "        words = clean(open(df, 'r', encoding='utf-8').read())\n",
    "        words = words.split()\n",
    "        for j, word in enumerate(words):\n",
    "            try:\n",
    "                ids[i, j] = word_list.index(word)\n",
    "            except:\n",
    "                # vector for unknown words\n",
    "                ids[i, j] = word_list.index('unk')\n",
    "            finally:\n",
    "                if j >= max_seq_len:\n",
    "                    break\n",
    "            if logging:\n",
    "                sys.stdout.write('\\rCreating ids... {:,} of {:,}'.format(i+1, num_files))\n",
    "    # done creating...\n",
    "    if logging:\n",
    "        print('Done creating ids for {}'.format(' '.join(data_files[0].split('/')[:-1])))\n",
    "    \n",
    "    np.save(save_file, ids)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 250)\n"
     ]
    }
   ],
   "source": [
    "ids = get_ids(files, word_list, max_seq_len=max_seq_len, save_file=ids_matrix_file, logging=True)\n",
    "print(ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations = 50,000\t Save interval = 500\n"
     ]
    }
   ],
   "source": [
    "batch_size = 24\n",
    "num_classes = 2\n",
    "lstm_units = 64\n",
    "dropout = 0.80  # 20% dropout\n",
    "learning_rate = 1e-3\n",
    "iterations = 50000\n",
    "save_interval = int(iterations / 100)\n",
    "print('Iterations = {:,}\\t Save interval = {:,}'.format(iterations, save_interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training and testing batch helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros(shape=[batch_size, max_seq_len])\n",
    "    for i in range(batch_size):\n",
    "        if (i % 2 == 0):\n",
    "            num = np.random.randint(1, 11499)\n",
    "            labels.append([1, 0])\n",
    "        else:\n",
    "            num = np.random.randint(13499, 24999)\n",
    "            labels.append([0, 1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batch_size, max_seq_len])\n",
    "    for i in range(batch_size):\n",
    "        num = np.random.randint(11499, 13499)\n",
    "        if (num <= 12499):\n",
    "            labels.append([1, 0])\n",
    "        else:\n",
    "            labels.append([0, 1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Resetting `tensorflow`'s default `Graph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Defining the placeholder variables\n",
    "\n",
    "As with most Tensorflow graphs, we’ll now need to specify two placeholders, one for the inputs into the network, and one for the labels. The most important part about defining these placeholders is understanding each of their dimensionalities.\n",
    "\n",
    "The labels placeholder represents a set of values, each either [1, 0] or [0, 1], depending on whether each training example is positive or negative i.e. **`batch_size x num_classes`**. Each row in the integerized input placeholder represents the integerized representation of each training example that we include in our batch i.e **`batch_size x max_seq_len`**\n",
    "\n",
    "![Placeholder dimensions](Images/SentimentAnalysis12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, shape=[batch_size, max_seq_len])\n",
    "y = tf.placeholder(tf.float32, shape=[batch_size, num_classes])\n",
    "y_true = tf.argmax(y, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once we have our input data placeholder, we’re going to call the **`tf.nn.embedding_lookup()`** function in order to get our word vectors. The call to that function will return a 3-D Tensor of dimensionality **_batch size by max sequence length by word vector dimensions._** In order to visualize this 3-D tensor, you can simply think of each data point in the integerized input tensor as the corresponding D dimensional vector that it refers to.\n",
    "![Lookup](Images/SentimentAnalysis13.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(24, 250, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "embedding = tf.nn.embedding_lookup(word_vectors, X)\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now that we have the `embedding` in the format that we want, let’s look at how we can feed this input into an **LSTM network**. We’re going to call the **`tf.contrib.rnn.BasicLSTMCell`** function. This function takes in an integer for the number of LSTM units that we want. This is one of the hyperparameters that will take some tuning to figure out the optimal value. We’ll then wrap that LSTM cell in a dropout layer by calling the **`tf.contrib.rnn.DropoutWrapper`** function to help prevent the network from overfitting.\n",
    "\n",
    "Finally, we’ll feed both the LSTM cell and the 3-D tensor full of input `embedding` into a function called **`tf.nn.dynamic_rnn`**. This function is in charge of unrolling the whole network and creating a pathway for the `embedding` to flow through the RNN graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function dynamic_rnn in module tensorflow.python.ops.rnn:\n",
      "\n",
      "dynamic_rnn(cell, inputs, sequence_length=None, initial_state=None, dtype=None, parallel_iterations=None, swap_memory=False, time_major=False, scope=None)\n",
      "    Creates a recurrent neural network specified by RNNCell `cell`.\n",
      "    \n",
      "    Performs fully dynamic unrolling of `inputs`.\n",
      "    \n",
      "    `Inputs` may be a single `Tensor` where the maximum time is either the first\n",
      "    or second dimension (see the parameter\n",
      "    `time_major`).  Alternatively, it may be a (possibly nested) tuple of\n",
      "    Tensors, each of them having matching batch and time dimensions.\n",
      "    The corresponding output is either a single `Tensor` having the same number\n",
      "    of time steps and batch size, or a (possibly nested) tuple of such tensors,\n",
      "    matching the nested structure of `cell.output_size`.\n",
      "    \n",
      "    The parameter `sequence_length` is optional and is used to copy-through state\n",
      "    and zero-out outputs when past a batch element's sequence length. So it's more\n",
      "    for correctness than performance.\n",
      "    \n",
      "    Args:\n",
      "      cell: An instance of RNNCell.\n",
      "      inputs: The RNN inputs.\n",
      "    \n",
      "        If `time_major == False` (default), this must be a `Tensor` of shape:\n",
      "          `[batch_size, max_time, ...]`, or a nested tuple of such\n",
      "          elements.\n",
      "    \n",
      "        If `time_major == True`, this must be a `Tensor` of shape:\n",
      "          `[max_time, batch_size, ...]`, or a nested tuple of such\n",
      "          elements.\n",
      "    \n",
      "        This may also be a (possibly nested) tuple of Tensors satisfying\n",
      "        this property.  The first two dimensions must match across all the inputs,\n",
      "        but otherwise the ranks and other shape components may differ.\n",
      "        In this case, input to `cell` at each time-step will replicate the\n",
      "        structure of these tuples, except for the time dimension (from which the\n",
      "        time is taken).\n",
      "    \n",
      "        The input to `cell` at each time step will be a `Tensor` or (possibly\n",
      "        nested) tuple of Tensors each with dimensions `[batch_size, ...]`.\n",
      "      sequence_length: (optional) An int32/int64 vector sized `[batch_size]`.\n",
      "      initial_state: (optional) An initial state for the RNN.\n",
      "        If `cell.state_size` is an integer, this must be\n",
      "        a `Tensor` of appropriate type and shape `[batch_size, cell.state_size]`.\n",
      "        If `cell.state_size` is a tuple, this should be a tuple of\n",
      "        tensors having shapes `[batch_size, s] for s in cell.state_size`.\n",
      "      dtype: (optional) The data type for the initial state and expected output.\n",
      "        Required if initial_state is not provided or RNN state has a heterogeneous\n",
      "        dtype.\n",
      "      parallel_iterations: (Default: 32).  The number of iterations to run in\n",
      "        parallel.  Those operations which do not have any temporal dependency\n",
      "        and can be run in parallel, will be.  This parameter trades off\n",
      "        time for space.  Values >> 1 use more memory but take less time,\n",
      "        while smaller values use less memory but computations take longer.\n",
      "      swap_memory: Transparently swap the tensors produced in forward inference\n",
      "        but needed for back prop from GPU to CPU.  This allows training RNNs\n",
      "        which would typically not fit on a single GPU, with very minimal (or no)\n",
      "        performance penalty.\n",
      "      time_major: The shape format of the `inputs` and `outputs` Tensors.\n",
      "        If true, these `Tensors` must be shaped `[max_time, batch_size, depth]`.\n",
      "        If false, these `Tensors` must be shaped `[batch_size, max_time, depth]`.\n",
      "        Using `time_major = True` is a bit more efficient because it avoids\n",
      "        transposes at the beginning and end of the RNN calculation.  However,\n",
      "        most TensorFlow data is batch-major, so by default this function\n",
      "        accepts input and emits output in batch-major form.\n",
      "      scope: VariableScope for the created subgraph; defaults to \"rnn\".\n",
      "    \n",
      "    Returns:\n",
      "      A pair (outputs, state) where:\n",
      "    \n",
      "        outputs: The RNN output `Tensor`.\n",
      "    \n",
      "          If time_major == False (default), this will be a `Tensor` shaped:\n",
      "            `[batch_size, max_time, cell.output_size]`.\n",
      "    \n",
      "          If time_major == True, this will be a `Tensor` shaped:\n",
      "            `[max_time, batch_size, cell.output_size]`.\n",
      "    \n",
      "          Note, if `cell.output_size` is a (possibly nested) tuple of integers\n",
      "          or `TensorShape` objects, then `outputs` will be a tuple having the\n",
      "          same structure as `cell.output_size`, containing Tensors having shapes\n",
      "          corresponding to the shape data in `cell.output_size`.\n",
      "    \n",
      "        state: The final state.  If `cell.state_size` is an int, this\n",
      "          will be shaped `[batch_size, cell.state_size]`.  If it is a\n",
      "          `TensorShape`, this will be shaped `[batch_size] + cell.state_size`.\n",
      "          If it is a (possibly nested) tuple of ints or `TensorShape`, this will\n",
      "          be a tuple having the corresponding shapes.\n",
      "    \n",
      "    Raises:\n",
      "      TypeError: If `cell` is not an instance of RNNCell.\n",
      "      ValueError: If inputs is None or an empty list.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.dynamic_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(lstm_units)\n",
    "lstm_cell = tf.contrib.rnn.DropoutWrapper(cell=lstm_cell, output_keep_prob=dropout)\n",
    "# create RNN specified by the `lstm_cell` (performs fully dynamic unrolling of `embedding`)\n",
    "outputs, state = tf.nn.dynamic_rnn(cell=lstm_cell, inputs=embedding, dtype=tf.float32)\n",
    "# outputs is the RNN output while state is the final state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As a side note, another more advanced network architecture choice is to stack multiple LSTM cells on top of each other. This is where the final hidden `state` vector of the first LSTM feeds into the second. Stacking these cells is a great way to help the model retain more long term dependence information, but also introduces more parameters into the model, thus possibly increasing the training time, the need for additional training examples, and the chance of overfitting. For more information on how you can add stacked LSTMs to your model, check out Tensorflow's excellent [documentation](https://www.tensorflow.org/tutorials/recurrent#stacking_multiple_lstms).\n",
    "\n",
    "The first `output` of the dynamic RNN function can be thought of as the last hidden state vector. This vector will be reshaped and then multiplied by a final weight matrix and a bias term to obtain the final output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.truncated_normal(shape=[lstm_units, num_classes], mean=0, stddev=1.))\n",
    "b = tf.Variable(tf.zeros(shape=[num_classes]))\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "last = tf.gather(outputs, int(outputs.get_shape()[0])-1)\n",
    "y_pred = tf.matmul(last, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluate Model's accuracy\n",
    "\n",
    "Next, we’ll define correct prediction and accuracy metrics to track how the network is doing. The correct prediction formulation works by looking at the index of the maximum value of the 2 output values, and then s\n",
    "eeing whether it matches with the training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_pred_true = tf.argmax(y_pred, axis=1)\n",
    "correct = tf.equal(y_pred_true, y_true)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loss function and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y, name='cross_entropy')\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Defining the `tf.Session`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tensorboard Visualization `tf.summary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "tf.summary.histogram('Weights', W)\n",
    "tf.summary.histogram('Biases', b)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "writer = tf.summary.FileWriter(logdir=log_path, graph=sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 30001/50000 [3:39:38<2:27:14,  2.26it/s]   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-205aec21f067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m    \u001b[0;31m# Next Batch of reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTrainBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Write summary to Tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(iterations), desc='Training'):\n",
    "   # Next Batch of reviews\n",
    "    X_batch, y_batch = getTrainBatch();\n",
    "    sess.run(train_step, {X: X_batch, y: y_batch})\n",
    "\n",
    "    # Write summary to Tensorboard\n",
    "    if (i % 50 == 0):\n",
    "        summary = sess.run(merged, {X: X_batch, y: y_batch})\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "    # Save the network every 10,000 training iterations\n",
    "    if (i % save_interval == 0 and i == iterations-1):\n",
    "        save_path = saver.save(sess, save_path=pre_trained_path, global_step=i)\n",
    "        tqdm.write('Saved to {}'.format(save_path))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# saver.restore(sess, tf.train.latest_checkpoint(chkpt_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Test data `accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 100.00%\n",
      "Accuracy for this batch: 83.33%\n",
      "Accuracy for this batch: 87.50%\n",
      "Accuracy for this batch: 66.67%\n",
      "Accuracy for this batch: 79.17%\n",
      "Accuracy for this batch: 95.83%\n",
      "Accuracy for this batch: 75.00%\n",
      "Accuracy for this batch: 91.67%\n",
      "Accuracy for this batch: 95.83%\n",
      "Accuracy for this batch: 83.33%\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    X_batch, y_batch = getTestBatch();\n",
    "    print(\"Accuracy for this batch: {:.2%}\".format(sess.run(accuracy, {X: X_batch, y: y_batch})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_embedding_matrix(sentence):\n",
    "    matrix = np.zeros(shape=[batch_size, max_seq_len], dtype=np.int32)\n",
    "    clean_sent = clean(sentence)\n",
    "    split = clean_sent.split()\n",
    "    for i, word in enumerate(split):\n",
    "        try:\n",
    "            matrix[0, i] = word_list.index(word)\n",
    "        except ValueError:\n",
    "            matrix[0, i] = word_list.index('unk')  # Vector for unkown words\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test(text):\n",
    "\n",
    "    text_embedding = get_embedding_matrix(text)\n",
    "    sentiment = sess.run(y_pred, feed_dict={X: text_embedding})[0]\n",
    "    return np.argmax(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a movie review: I'm not a fan. It's didn't interest me\n",
      "Negative sentiment\n"
     ]
    }
   ],
   "source": [
    "text = input('Enter a movie review: ')\n",
    "sentiment = test(text)\n",
    "\n",
    "pred = 'Positive sentiment' if sentiment else 'Negative sentiment'\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a movie review: I can't wait to watch it again!\n",
      "Positive sentiment\n"
     ]
    }
   ],
   "source": [
    "text = input('Enter a movie review: ')\n",
    "sentiment = test(text)\n",
    "\n",
    "pred = 'Positive sentiment' if sentiment else 'Negative sentiment'\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
