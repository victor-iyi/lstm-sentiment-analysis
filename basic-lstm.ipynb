{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# LSTM Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Vanilla libraries\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# 3rd-party libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Helper library\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## File paths & pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'datasets/'\n",
    "\n",
    "saved_w2id = 'saved/word2id.pkl'\n",
    "ids_matrix_file = 'saved/idsMatrix.npy'\n",
    "\n",
    "tensorboard_dir = 'tensorboard/'\n",
    "logdir = os.path.join(tensorboard_dir, 'log')\n",
    "save_path = 'models/'\n",
    "trained_model_path = os.path.join(save_path, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Word count and average words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(saved_w2id):\n",
    "    w2id = Word2ID(data_dir=data_dir)\n",
    "    # Save it!\n",
    "    with open(saved_w2id, mode='wb') as f:\n",
    "        pickle.dump(obj=w2id, file=f)\n",
    "else:\n",
    "    f = open(saved_w2id, mode='rb')\n",
    "    w2id = pickle.load(file=f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train = w2id.features\n",
    "y_train = w2id.labels\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Recurrent Neural Network\n",
    "\n",
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "max_seq_len = w2id.max_seq_len\n",
    "word_vector_size = 50  # 50-300\n",
    "\n",
    "# Model\n",
    "lstm_units = 128\n",
    "keep_prob = 0.8\n",
    "\n",
    "# Training\n",
    "learning_rate = 1e-3\n",
    "batch_size = 24\n",
    "iterations = 10000\n",
    "save_step = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## `tensorflow`'s Computational Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reset default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Model's placeholders\n",
    "X = tf.placeholder(tf.int32, shape=[batch_size, max_seq_len])\n",
    "y = tf.placeholder(tf.float32, shape=[batch_size, num_classes])\n",
    "y_true = tf.argmax(y, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Embedding lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# helper.GLOVE_VECTORS\n",
    "embedding = tf.nn.embedding_lookup(GLOVE_VECTORS, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### `LSTMCell`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(lstm_units)\n",
    "lstm_cell = tf.contrib.rnn.DropoutWrapper(cell=lstm_cell, output_keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "outputs, state = tf.nn.dynamic_rnn(lstm_cell, embedding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.truncated_normal(shape=[lstm_units, num_classes]), name='weight')\n",
    "b = tf.Variable(tf.zeros(shape=[num_classes]), name='bias')\n",
    "\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "layer = tf.gather(outputs, int(outputs.get_shape()[0]) - 1)\n",
    "y_hat = tf.matmul(layer, W) + b\n",
    "y_pred = tf.nn.softmax(y_hat)\n",
    "y_pred_true = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### `cross_entropy` `loss` & `optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=y_hat, labels=y)\n",
    "loss = tf.reduce_mean(x_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "correct = tf.equal(y_true, y_pred_true)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Running `tf.Session()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Saver and Writer\n",
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter(logdir=logdir, graph=sess.graph)\n",
    "\n",
    "# Tensorboard summary\n",
    "tf.summary.scalar('loss', loss)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "tf.summary.histogram('weight', W)\n",
    "tf.summary.histogram('bias', b)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "# Load pretrained or create save_path\n",
    "if tf.gfile.Exists(save_path):\n",
    "    if len(os.listdir(save_path)) > 1:\n",
    "        saver.restore(sess=sess, save_path=tf.train.latest_checkpoint(save_path))\n",
    "else:\n",
    "    tf.gfile.MakeDirs(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clocking the time taken so far...\n",
    "train_start = datetime.now()\n",
    "for i in range(iterations):\n",
    "    # Next batchwriter = tf.summary.FileWriter(logdir=logdir, graph=sess.graph)\n",
    "    X_batch, y_batch = w2id.next_batch(batch_size=batch_size)\n",
    "    feed_dict = {X: X_batch, y: y_batch}\n",
    "    sess.run(train_step, feed_dict=feed_dict)\n",
    "    if i % save_step == 0:\n",
    "        # Save\n",
    "        saver.save(sess=sess, save_path=trained_model_path, global_step=i)\n",
    "        # Add summary\n",
    "        summary = sess.run(merged, feed_dict=feed_dict)\n",
    "        writer.add_summary(summary, global_step=i)\n",
    "    sys.stdout.write('\\r{:,} of {:,}\\tTime taken: {}'.format(i+1, iterations, datetime.now()-train_start))\n",
    "\n",
    "# Close the FileWriter\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Testing!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_tests = 2\n",
    "for i in range(n_tests):\n",
    "    X_batch, y_batch = w2id.next_batch(batch_size=batch_size)\n",
    "    feed_dict = {X: X_batch, y: y_batch}\n",
    "    acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "    print('Accuracy {:,} = {:.2%}'.format(i+1, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test(text):\n",
    "    text_embedding = w2id.get_embeding_ids(text)\n",
    "    sentiment = sess.run(y_pred, feed_dict={X: text_embedding})[0]\n",
    "    return np.argmax(sentiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
